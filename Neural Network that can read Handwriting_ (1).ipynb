{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c69afd",
   "metadata": {},
   "source": [
    "# TASK 2 OF BHARAT-INTERN INTERNSHIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0dae6",
   "metadata": {},
   "source": [
    "## Handwritten Recognition using neural network by Suraj Yadav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c477dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# numpy is aliased as np\n",
    "import pandas as pd\n",
    "# pandas is aliased as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# pyplot is aliased as plt\n",
    "import tensorflow as tf\n",
    "# tensorflow is aliased as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6e959",
   "metadata": {},
   "source": [
    "### load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f17464",
   "metadata": {},
   "source": [
    "The MNIST dataset is a widely used dataset in machine learning and consists of a set of 60,000 training images and \n",
    "10,000 test images of handwritten digits from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53423aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ce4abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "## checking the shapes of training and testing dataset\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8559338b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# displayiing the data of x_train\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc2f3c",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b3541",
   "metadata": {},
   "source": [
    "1.Reshaping the input data which is work as a input for CNN<br>\n",
    "2.The original shape of x_train is (num_train_samples, 28, 28), where num_train_samples is the number of training samples,<br>     and 28 by 28 represents the dimensions of each image<br>\n",
    "3.CNN takes the input data with the shape,(num_samples, height, width, channels)..<br>\n",
    "4.Images are grayscale, so the channel value is set to 1<br>\n",
    "5.After reshaping the datatype of array will change to float32 which is common data type used in deep learning.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1d8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce5989",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7074b0",
   "metadata": {},
   "source": [
    "The original pixel values in the MNIST dataset range from 0 to 255, where 0 represents black and 255 represents white.<br> Dividing the pixel values by 255 normalizes the data so that the values are scaled between 0 and 1.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127d8fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66371bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fed068",
   "metadata": {},
   "source": [
    "### Build the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d087a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28435268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                77450     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,266\n",
      "Trainable params: 96,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed047cb5",
   "metadata": {},
   "source": [
    "This summary shows that the model has five layers:\n",
    "\n",
    "1. Conv2D: This layer performs convolutional operations on the input. It has 32 filters of size 3x3 and applies the<br> \n",
    "    ReLU activation function. The output shape is (None, 26, 26, 32), where None represents the batch size.<br>\n",
    "\n",
    "2. MaxPooling2D: This layer performs max pooling, which reduces the spatial dimensions of the input.<br> \n",
    "    It uses a 2x2 pooling window. The output shape is (None, 13, 13, 32), as the pooling operation reduces each spatial<br> \n",
    "    dimension by a factor of 2.<br>\n",
    "\n",
    "3. Conv2D: This layer is similar to the previous Conv2D layer but has 64 filters instead of 32.<br> \n",
    "    The output shape is (None, 11, 11, 64).<br>\n",
    "\n",
    "4. Flatten: This layer flattens the previous output, converting it from a 4D tensor to a 2D tensor.<br> \n",
    "    The output shape is (None, 7744), where 7744 is the result of multiplying the spatial dimensions.<br>\n",
    "\n",
    "5. Dense: This layer is a fully connected layer with 10 units and applies the ReLU activation function.<br> \n",
    "   It takes the flattened input and produces an output of shape (None, 10), where 10 represents the number of classes in<br>\n",
    "   the classification task.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3087d4",
   "metadata": {},
   "source": [
    "### plot a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283626c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "#img = plt.imread('model.png')\n",
    "#plt.imshow(img)\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf93a1e",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f4052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c761d35",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee6afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 94s 48ms/step - loss: 0.1279 - accuracy: 0.9613 - val_loss: 0.0480 - val_accuracy: 0.9847\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.0421 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0315 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0287 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 63s 33ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0356 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0389 - val_accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.0358 - val_accuracy: 0.9901\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0390 - val_accuracy: 0.9905\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0547 - val_accuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261021f4490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057c4d6",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51b96893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0547 - accuracy: 0.9881\n",
      "Test accuracy: 0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48093a12",
   "metadata": {},
   "source": [
    "### Displaying a Grayscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9e96a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[55]\n",
    "plt.imshow(np.squeeze(img) ,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd21c73",
   "metadata": {},
   "source": [
    "### Predicting the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17fc5730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 358ms/step\n",
      "Predicted class: 8\n"
     ]
    }
   ],
   "source": [
    "img= img.reshape(1, 28, 28, 1)\n",
    "a= model.predict([img])\n",
    "predicted_class = np.argmax(a)\n",
    "print(\"Predicted class: {}\".format(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f93918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
